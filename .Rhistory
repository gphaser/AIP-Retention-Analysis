geom_point(mapping= aes(x=displ, y= hwy, color = class))+
facet_grid(drv ~ cyl)
ggplot(data = mpg)+
geom_smooth(mapping= aes(x=displ, y= hwy, linetype = dvr))
ggplot(data = mpg)+
geom_smooth(mapping= aes(x=displ, y= hwy, linetype = drv))
ggplot(data = mpg)+
geom_smooth(mapping= aes(x=displ, y= hwy, linetype = drv, color = drv))
ggplot(data = mpg)+
geom_point(mapping= aes(x=displ, y= hwy, color = class))+
geom_smooth(mapping= aes(x=displ, y= hwy, linetype = drv, color = drv))
ggplot(data = mpg)+
geom_point(mapping= aes(x=displ, y= hwy, color = class))+
geom_smooth(mapping= aes(x=displ, y= hwy))
ggplot(data = mpg, mapping= aes(x=displ, y= hwy)+
geom_point()+
geom_smooth()
ggplot(data = mpg, mapping= aes(x=displ, y= hwy)+
geom_point(color = class)+
geom_smooth()
geom_point(mapping= aes(color = class))+
ggplot(data = diamonds)+
geom_bar(mapping= aes(x=cut, color = class))
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, color = class))
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cuts))
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut))
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, color = cut)
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, color = cut))
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))
source('~/Desktop/Data Science/GGPlots.R')
source('~/Desktop/Data Science/GGPlots.R')
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
coord_flip()
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
ylab("g of diamonds")+
xlab( "")+
ggtitle("My Awsome Plot")
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
ylab("g of diamonds")+
xlab( "")+
ggtitle("My Awsome Plot")+
theme_gray()
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
ylab("g of diamonds")+
xlab( "")+
ggtitle("My Awsome Plot")+
theme_gray()
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
ylab("g of diamonds")+
xlab( "")+
ggtitle("My Awsome Plot")+
theme_dark()
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
ylab("g of diamonds")+
xlab( "")+
ggtitle("My Awsome Plot")+
theme_minimal()
install.packages("ggthemes")
library(ggthemes)
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
ylab("g of diamonds")+
xlab( "")+
ggtitle("My Awsome Plot")+
theme_gdocs()
# need to library(ggplot) and library(ggthemes)
ggplot(data = mpg)+
geom_point(mapping= aes(x=displ, y= hwy, color = class))+
facet_grid(drv ~ cyl)
ggplot(data = diamonds) +
geom_bar(mapping= aes(x=cut, fill = cut))+
ylab("g of diamonds")+
xlab( "")+
ggtitle("My Awsome Plot")+
theme_gdocs()
library(LaTeX)
library('LaTeX')
library('latex')
library('tinytex')
tinytex::install_tinytex()
library(tidyverse)
library(tidyverse)
install.packages("rticales")
install.packages("rticles")
library(tidyverse)
ds <- read_csv("~/Desktop/Data Science/ramen-ratings.csv")
# build the traing/testing sets
indexies <- sample(1:nrow(ds), as.int(0.7*nrow(ds)))
trainData <-ds[indexies,]
testData <-ds[~indexies,]
# build the traing/testing sets
indexies <- sample(1:nrow(ds), as.int(0.7*nrow(ds)))
# build the traing/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.7*nrow(ds)))
testData <- ds[~indexies,]
testData <- ds[-indexies,]
trainData <- ds[indexies,]
library(rpart)
library(rattle)
install.packages("rpart")
install.packages("rpart")
install.packages("rattle")
# Demo Decision trees
library(tidyverse)
library(rpart) # for building decision trees
library(rattle) # for graficly displaying decision trees
# read in the data set
ds <- read_csv("~/Desktop/Data Science/ramen-ratings.csv")
# build the traing/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.7*nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[-indexies,]
# build decision tree
rpart(formula = tasty_ramen - country+stars , data = trainData, method = "class")
rpart(formula = `tasty ramen` - country+stars , data = trainData, method = "class")
rpart(formula = `Tasty ramen` ~ country+stars , data = trainData, method = "class")
rpart(formula = `Tasty Ramen` ~ country+stars , data = trainData, method = "class")
rpart(formula = `Rating` ~ country + stars , data = trainData, method = "class")
rpart(formula = `Top 10` ~ country + stars , data = trainData, method = "class")
rpart(formula = `Top 10` ~ stars , data = trainData, method = "class")
rpart(formula = `Top Ten` ~ stars , data = trainData, method = "class")
rpart(formula = `Top Ten` ~ countries+stars , data = trainData, method = "class")
rpart(formula = `Top Ten` ~ Country+Stars , data = trainData, method = "class")
library(naivebayes)
load(naivebayes)
install.packages(naivebayes)
install.packages("naivebayes")
library(naivebayes)
model <- naive_bayes(drv ~ fl+class, data ~ trainData)
# Naive Bayes DEMO
library(tidyverse)
library(naivebayes)
# read in the dataset
# ds <- read_csv('~)
ds <- mpg
# build the training/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.76*nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[indexies,]
model <- naive_bayes(drv ~ fl+class, data ~ trainData)
# Naive Bayes DEMO
library(tidyverse)
library(naivebayes)
# read in the dataset
# ds <- read_csv('~)
ds <- mpg
# build the training/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.75 * nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[~indexies,]
model <- naive_bayes(drv ~ fl+class, data ~ trainData)
model <- naive_bayes(drv ~ fl + class, data = trainData, laplace = 1)
# Naive Bayes DEMO
library(tidyverse)
library(naivebayes)
# read in the dataset
# ds <- read_csv('~)
ds <- mpg
# build the training/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.75 * nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[~indexies,]
#build the naive bayes model
model <- naive_bayes(drv ~ fl + class, data = trainData, laplace = 1)
predict(model, testData[1,])
# Naive Bayes DEMO
library(tidyverse)
library(naivebayes)
# read in the dataset
# ds <- read_csv('~)
ds <- mpg
# build the training/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.75 * nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[~indexies,]
#build the naive bayes model
model <- naive_bayes(drv ~ fl + class, data = trainData, laplace = 1)
predict(model, testData[1,], type = 'prob')
# Naive Bayes DEMO
library(tidyverse)
library(naivebayes)
# read in the dataset
# ds <- read_csv('~)
ds <- mpg
# build the training/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.75 * nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[~indexies,]
#build the naive bayes model
model <- naive_bayes(drv ~ fl + class, data = trainData, laplace = 1)
predict(model, testData[1,], type = "prob")
# Demo Decision trees
library(tidyverse)
library(rpart) # for building decision trees
library(rattle) # for graficly displaying decision trees
# read in the data set
ds <- read_csv("~/Desktop/Data Science/ramen-ratings.csv")
# build the traing/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.7*nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[-indexies,]
# build decision tree
rpart(formula = `Top Ten` ~ Country+Stars , data = trainData, method = "class")
# Naive Bayes DEMO
library(tidyverse)
library(naivebayes)
# read in the dataset
# ds <- read_csv('~)
ds <- mpg
# build the training/testing sets
indexies <- sample(1:nrow(ds), as.integer(0.75 * nrow(ds)))
trainData <- ds[indexies,]
testData <- ds[~indexies,]
#build the naive bayes model
model <- naive_bayes(drv ~ fl + class, data = trainData, laplace = 1)
predict(model, testData[1,], type = "prob")
iris''
iris
install.packages("factoextra")
library(factoextra) # for visualzing
iris
#kMEANS EXAMPLE (Clustering)
#import needed libraries
library(factoextra) # for visualzing
#Using iris dataset, centers = k = number of clusters to create (you may not know this)
kmeans(iris[,1:4], centers = 3, )
#kMEANS EXAMPLE (Clustering)
#import needed libraries
library(factoextra) # for visualzing
#Using iris dataset, centers = k = number of clusters to create (you may not know this)
kmeans(iris[,1:4], centers = 3)
#kMEANS EXAMPLE (Clustering)
#import needed libraries
library(factoextra) # for visualzing
#Using iris dataset, centers = k = number of clusters to create (you may not know this) minimum = 2
km <- kmeans(iris[,1:4], centers = 3)
# this is the only line needed to do this unsupervized learning.
cbind(iris, km$cluster)
#kMEANS EXAMPLE (Clustering)
#import needed libraries
library(factoextra) # for visualzing
#Using iris dataset, centers = k = number of clusters to create (you may not know this) minimum = 2
# Run Kmeans and make predictions
km <- kmeans(iris[,1:4], centers = 3)
# this is the only line needed to do this unsupervized learning.
cbind(iris, km$cluster) # adds the cluster to the dataset.
fviz_cluster(km, iris[,1:4])
#kMEANS EXAMPLE (Clustering)
#import needed libraries
library(factoextra) # for visualzing
#Using iris dataset, centers = k = number of clusters to create (you may not know this) minimum = 2
# Run Kmeans and make predictions
km <- kmeans(iris[,1:2], centers = 3)
# this is the only line needed to do this unsupervized learning.
cbind(iris, km$cluster) # adds the cluster to the dataset.
fviz_cluster(km, iris[,1:2])
#kMEANS EXAMPLE (Clustering)
#import needed libraries
library(factoextra) # for visualzing
#Using iris dataset, centers = k = number of clusters to create (you may not know this) minimum = 2
# Run Kmeans and make predictions
km <- kmeans(iris[,1:4], centers = 3)
# this is the only line needed to do this unsupervized learning.
cbind(iris, km$cluster) # adds the cluster to the dataset.
fviz_cluster(km, iris[,1:4])
install.packages("nycflights13")
#DPLYR EXAMPLES
library(nycflights13)
library(tidyverse)
filter()
ds <- filter(flights, month == 1 | month == 3)
filter(flights, dest == "IAH" | dest == "HOU" )
View(ds)
#DPLYR EXAMPLES
#included library
library(nycflights13)
library(tidyverse)
ds <- filter(flights, month == 1 | month == 3)
# find flights that arive with a delay of 2 or more hours
filter(flights, arr_delay >= 2)
# find all flights to huston (IAH or HOU)
filter(flights, dest == "IAH" | dest == "HOU" )
# find all flights opperated by United American or Delta
filter(flights, carrier == "UA" | carrier == "DL")
# find all flights that departed in Jully August or September
filter(flights, dest == "IAH" | dest == "HOU" )
# find flights that arived more than 2 hours late
filter(flights, arr_delat >120)
# find flights that departed between midnight and 6am (inclusive)
filter(flights, dep_time <= 600 || dep_time == 2400 )
select(flights, month, year, everything())
select(flights, year:day)
ds2 <- mutate(flights, air_time_hours = air_time / 60)
mutate(flights, gain - arr_delay, speed-distance / air_time*60)
mutate(flights, goin - arr_delay, speed-distance / air_time*60)
mutate(flights, gain = arr_delay-dep_delay, speed = distance / air_time*60)
transmute(flights, dep_time_mins  = dep_time %/% 100 * 60 + dep_time %% 100)
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
read.csv("~/Desktop/Data Science/R files/country_vaccinations.csv")
# Read in csv and store it
ds <- read.csv("~/Desktop/Data Science/R files/country_vaccinations.csv")
View(ds)
View(ds)
# import library
library(tidyverse)
library(ggplot2)
library(rpart)
library(rpart.plot)
# import data for training and test
ds_train <- read.csv("~/Desktop/Data Science/R files/titanic/train.csv")
ds_test <- read.csv("~/Desktop/Data Science/R files/titanic/test.csv")
# build the decision tree
model <- rpart(formula = Survived ~ Sex + Pclass, data = ds_train,
method = "class", control = list(cp = -1))
#display the decision tree
rpart.plot(model)
# make preditcions using the test set
predictions <- predict(model, ds_test, type = "class")
install.packages("shiny")
shiny::runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
runApp('Desktop/Data Science/Demo')
library(shiny); runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 2.R')
runApp('Desktop/Data Science/Demo/Shiny app 3.R')
runApp('Desktop/Data Science/Demo/Shiny app 3.R')
runApp('Desktop/Data Science/Demo/Shiny app 3.R')
runApp('Desktop/Data Science/Demo/Shiny app 3.R')
runApp('Desktop/Data Science/Demo/Shiny app 3.R')
install.packages("leaflet")
library(leaflet)
map <- (leaflet)
map
map <- leaflet()
library(leaflet)
map <- leaflet()
map
library(leaflet)
map <- leaflet()
map <- addTiles(map)
library(leaflet)
map <- leaflet()
map <- addTiles(map)
map
library(leaflet)
map <- leaflet()
map <- addTiles(map)
map <- addMarkers(map, lng = 174.768, lat = 36.85, popup = "a place")
map
library(leaflet)
map <- leaflet()
map <- addTiles(map)
map <- addMarkers(map, lng = 194.768, lat = 36.85, popup = "a place")
map
library(leaflet)
map <- leaflet()
map <- addTiles(map)
map <- addMarkers(map, lng = 344.768, lat = 36.85, popup = "a place")
map
map <- addMarkers(map, lng = 344.768, lat = -36.85, popup = "a place")
library(leaflet)
map <- leaflet()
map <- addTiles(map)
map <- addMarkers(map, lng = 344.768, lat = -36.85, popup = "a place")
map
library(leaflet)
map <- leaflet()
map <- addTiles(map)
map <- addMarkers(map, lng = 174.768, lat = -36.85, popup = "a place")
map
library(leaflet)
map <- leaflet()
map <- addTiles(map)
map <- addMarkers(map, lng = 174.768, lat = -36.85, popup = "a place in new zeland")
map
install.packages("magick")
library(magick)
#write an image
image_write(tiger, path = "tiger.png", format = png)
# load a svg image
tiger <- image_read_svg("http://http://jeroen.github.io/images/tiger.svg", width = 350)
tiger
#write an image
image_write(tiger, path = "tiger.png", format = png)
tiger
# load a svg image
tiger <- image_read_svg("https://http://jeroen.github.io/images/tiger.svg", width = 350)
# load a svg image
tiger <- image_read_svg("https://jeroen.github.io/images/tiger.svg", width = 350)
tiger
#write an image
image_write(tiger, path = "tiger.png", format = png)
tiger
tiger <- image_read_svg("https://jeroen.github.io/images/tiger.svg", width = 350)
library(magick)
tiger <- image_read_svg("https://jeroen.github.io/images/tiger.svg", width = 350)
frink <- image_read("https://jeroen.github.io/images/frink.png", width = 350)
frink <- image_read("https://jeroen.github.io/images/frink.png")
frink <- image_read("https://jeroen.github.io/images/frink.png")
image_border(frink, "hotpink")
# load a svg image
tiger <- image_read_svg("http://jeroen.github.io/images/tiger.svg", width = 350)
tiger <- image_read_svg("http://jeroen.github.io/images/tiger.svg", width = 350)
tiger
frink <- image_read("https://jeroen.github.io/images/frink.png")
image_background(image_border(frink, "hotpink"),"blue")
image_border(image_background(frink, "hotpink"),"blue")
image_border(image_background(frink, "pink"),"blue")
library(esquisse)
esquisse()
library(esquisse)
esquisser()
install.packages("tidymodels")
library(tidymodels)
library(tidymodels)
iris_split <- initial_split(iris, prop = .6)
iris_split <- initial_split(iris, prop = .6)
iris_split <- initial_split(iris, prop = 0.6)
training(iris_split)
testing(iris_split)
iris_split
iris_recipi <- iris_train %>%
recipe(Species ~ .) %>%
step_corr(all_predictors()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep()
iris_split <- initial_split(iris, prop = 0.6)
iris_train <- training(iris_split)
iris_test <- testing(iris_split)
iris_recipi <- iris_train %>%
recipe(Species ~ .) %>%
step_corr(all_predictors()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep()
iris_testing <- iris_recipe %>%
bake(iris_test)
iris_training <- iris_recipe %>%
juice(iris_train)
iris_recipe <- iris_train %>%
recipe(Species ~ .) %>%
step_corr(all_predictors()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep()
iris_testing <- iris_recipe %>%
bake(iris_test)
iris_training <- iris_recipe %>%
juice(iris_train)
library(tidymodels)
#sample the data
iris_split <- initial_split(iris, prop = 0.6)
iris_train <- training(iris_split)
iris_test <- testing(iris_split)
#preprocess the data
iris_recipe <- iris_train %>%
recipe(Species ~ .) %>%
step_corr(all_predictors()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep()
iris_testing <- iris_recipe %>%
bake(iris_test)
iris_training <- juice(iris_train)
iris_training <- juice(iris_train)
iris_training <- juice(iris_recipe)
View(iris_recipi)
